#!/bin/bash
set -e

MODE="${1:-}"   # –ø—É—Å—Ç–æ = —Ç–æ–ª—å–∫–æ –æ—Ç—á—ë—Ç, --move = –ø–µ—Ä–µ–Ω–æ—Å –≤ _unused_trash

python3 - <<'PY'
import re, os, shutil, sys
from pathlib import Path

proj = Path(".").resolve()

content = proj / "content"
posters = content / "posters"
if not posters.exists():
    print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ content/posters. –ó–∞–ø—É—Å—Ç–∏ –∏–∑ –ø–∞–ø–∫–∏ InteractivePosters/")
    sys.exit(1)

reports = proj / "reports"
reports.mkdir(exist_ok=True)

trash = proj / "_unused_trash"
move_mode = ("--move" in sys.argv)

# –ß—Ç–æ —Å—á–∏—Ç–∞–µ–º "–∞—Å—Å–µ—Ç–∞–º–∏" (–º–æ–∂–µ—à—å —Ä–∞—Å—à–∏—Ä–∏—Ç—å)
ASSET_EXT = {".png",".jpg",".jpeg",".gif",".webp",".svg",".ico",
             ".css",".js",".json",
             ".ttf",".otf",".woff",".woff2",
             ".mp3",".wav",".mp4",".webm",
             ".pdf"}

# –ì–¥–µ –∏—Å–∫–∞—Ç—å –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –Ω–∞ —É–¥–∞–ª–µ–Ω–∏–µ
CANDIDATE_DIRS = [
    content,            # –≤—Å—ë –≤–Ω—É—Ç—Ä–∏ content (–æ—Å—Ç–æ—Ä–æ–∂–Ω–æ, –Ω–æ –º—ã —Ñ–∏–ª—å—Ç—Ä—É–µ–º –ø–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—é)
]

# –ì–¥–µ –∏—Å–∫–∞—Ç—å —Å—Å—ã–ª–∫–∏ (–∏—Å—Ç–æ—á–Ω–∏–∫–∏)
SOURCE_DIRS = [
    posters,
    content,            # —á—Ç–æ–±—ã –ø–æ–π–º–∞—Ç—å —Å—Å—ã–ª–∫–∏ –∏–∑ –æ–±—â–∏—Ö css/js/json
]

# –§–∞–π–ª—ã, –≤ –∫–æ—Ç–æ—Ä—ã—Ö –∏—â–µ–º —Å—Å—ã–ª–∫–∏ (—Ç–µ–∫—Å—Ç–æ–≤—ã–µ)
SOURCE_TEXT_EXT = {".html",".htm",".css",".js",".json",".txt",".md",".py"}
ALWAYS_KEEP = {
    (content / "subjects.json").resolve(),
    (content / "shanyrak_icon.svg").resolve(),
    (content / "locales" / "ru.json").resolve(),
    (content / "locales" / "kz.json").resolve(),
    (content / "locales" / "en.json").resolve(),
}

# --- —Å–±–æ—Ä –≤—Å–µ—Ö –∞—Å—Å–µ—Ç–æ–≤-–∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ ---
candidates = []
for base in CANDIDATE_DIRS:
    for p in base.rglob("*"):
        if p.is_file() and p.suffix.lower() in ASSET_EXT:
            # –Ω–µ —Ç—Ä–æ–≥–∞–µ–º –æ—Ç—á—ë—Ç—ã/–∫–æ—Ä–∑–∏–Ω—É/–±—ç–∫–∞–ø—ã
            if "_unused_trash" in p.parts or "reports" in p.parts or "backup" in p.parts:
                continue
            candidates.append(p)

# --- —Å–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Å—Å—ã–ª–∫–∏ –∏–∑ –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤ ---
src_href_re = re.compile(r'''(?:src|href)\s*=\s*["']([^"']+)["']''', re.I)
css_url_re   = re.compile(r'''url\(\s*(['"]?)(.*?)\1\s*\)''', re.I)

def norm_url(u: str) -> str:
    u = (u or "").strip()
    if not u:
        return ""
    u = u.split("#")[0].split("?")[0].strip()
    return u

def is_ignorable(u: str) -> bool:
    lu = u.lower()
    return (not u or u.startswith("#") or
            lu.startswith(("http:","https:","data:","mailto:","tel:","javascript:","about:","qrc:","qt:")))

used = set()

# –°–∫–∞–Ω–∏—Ä—É–µ–º –∏—Å—Ö–æ–¥–Ω–∏–∫–∏, –≤—ã—Ç–∞—Å–∫–∏–≤–∞–µ–º —Å—Å—ã–ª–∫–∏ –∏ –ø—ã—Ç–∞–µ–º—Å—è —Ä–µ–∑–æ–ª–≤–∏—Ç—å –≤ —Ñ–∞–π–ª—ã
sources_scanned = 0
for base in SOURCE_DIRS:
    for f in base.rglob("*"):
        if not f.is_file():
            continue
        if f.suffix.lower() not in SOURCE_TEXT_EXT:
            continue
        sources_scanned += 1
        txt = f.read_text(encoding="utf-8", errors="ignore")

        urls = []
        urls += [norm_url(m.group(1)) for m in src_href_re.finditer(txt)]
        urls += [norm_url(m.group(2)) for m in css_url_re.finditer(txt)]

        for u in urls:
            if is_ignorable(u):
                continue

            # –∞–±—Å–æ–ª—é—Ç–Ω—ã–π –ø—É—Ç—å –≤–Ω—É—Ç—Ä–∏ content (–µ—Å–ª–∏ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å /)
            if u.startswith("/"):
                target = (content / u.lstrip("/")).resolve()
            else:
                target = (f.parent / u).resolve()

            # –µ—Å–ª–∏ —Å—Å—ã–ª–∫–∞ –≤–µ–¥—ë—Ç –Ω–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ñ–∞–π–ª ‚Äî –ø–æ–º–µ—á–∞–µ–º used
            if target.exists() and target.is_file():
                used.add(target)

# --- –≤—ã—á–∏—Å–ª—è–µ–º –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º–æ–µ ---
unused = [p for p in candidates if p not in used and p.resolve() not in ALWAYS_KEEP]


# --- –æ—Ç—á—ë—Ç—ã ---
unused_txt = reports / "unused_files.txt"
used_txt   = reports / "used_files_count.txt"

unused_txt.write_text("\n".join(str(p.relative_to(proj)) for p in sorted(unused)), encoding="utf-8")
used_txt.write_text(
    f"Sources scanned: {sources_scanned}\n"
    f"Candidates: {len(candidates)}\n"
    f"Used: {len(used)}\n"
    f"Unused: {len(unused)}\n",
    encoding="utf-8"
)

print("‚úÖ Audit complete")
print(used_txt.read_text(encoding="utf-8").strip())
print(f"üìÑ –û—Ç—á—ë—Ç: {unused_txt}")

# --- –±–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø–µ—Ä–µ–º–µ—â–µ–Ω–∏–µ –≤ –∫–æ—Ä–∑–∏–Ω—É ---
if move_mode:
    trash.mkdir(exist_ok=True)
    moved = 0
    for p in unused:
        rel = p.relative_to(proj)
        dst = trash / rel
        dst.parent.mkdir(parents=True, exist_ok=True)
        # –µ—Å–ª–∏ —Ñ–∞–π–ª —É–∂–µ —Ç–∞–º –µ—Å—Ç—å ‚Äî –¥–æ–±–∞–≤–∏–º —Å—É—Ñ—Ñ–∏–∫—Å
        if dst.exists():
            dst = dst.with_name(dst.stem + "_dup" + dst.suffix)
        shutil.move(str(p), str(dst))
        moved += 1
    print(f"üóë –ü–µ—Ä–µ–º–µ—â–µ–Ω–æ –≤ {trash}: {moved} —Ñ–∞–π–ª–æ–≤ (–ù–ï —É–¥–∞–ª–µ–Ω–æ –Ω–∞–≤—Å–µ–≥–¥–∞)")

PY

